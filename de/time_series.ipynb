{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pmxv2ioyCRw"
      },
      "source": [
        "##### Copyright 2019 Die TensorFlow-Autoren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b-2ShX25yNWf"
      },
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# Zeitreihenvorhersage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Ilg92myRcw"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/time_series\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Auf TensorFlow.org anzeigen</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">In Google Colab ausführen</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Quelle auf GitHub anzeigen</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Notizbuch herunterladen</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU8C5qm_4vZb"
      },
      "source": [
        "Dieses Tutorial ist eine Einführung in die Zeitreihenprognose mit TensorFlow. Es erstellt einige verschiedene Arten von Modellen, einschließlich Convolutional and Recurrent Neural Networks (CNNs und RNNs).\n",
        "\n",
        "Dies wird in zwei Hauptteilen mit Unterabschnitten behandelt:\n",
        "\n",
        "- Prognose für einen einzelnen Zeitschritt:\n",
        "    - Ein einziges Merkmal.\n",
        "    - Alle Features.\n",
        "- Prognostizieren Sie mehrere Schritte:\n",
        "    - Single-Shot: Treffen Sie alle Vorhersagen auf einmal.\n",
        "    - Autoregressiv: Machen Sie jeweils eine Vorhersage und leiten Sie die Ausgabe zurück an das Modell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVhK72Pu1cJL"
      },
      "source": [
        "## Konfiguration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rZnJaGTWQw0"
      },
      "outputs": [

      ],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TokBlnUhWFw9"
      },
      "source": [
        "## Der Wetterdatensatz\n",
        "\n",
        "Dieses Tutorial verwendet einen <a href=\"https://www.bgc-jena.mpg.de/wetter/\" class=\"external\">Wetterzeitreihen-Datensatz</a> , der vom <a href=\"https://www.bgc-jena.mpg.de\" class=\"external\">Max-Planck-Institut für Biogeochemie</a> aufgezeichnet wurde.\n",
        "\n",
        "Dieser Datensatz enthält 14 verschiedene Merkmale wie Lufttemperatur, Luftdruck und Luftfeuchtigkeit. Diese wurden ab 2003 alle 10 Minuten erfasst. Aus Effizienzgründen verwenden Sie nur die zwischen 2009 und 2016 erfassten Daten. Dieser Abschnitt des Datensatzes wurde von François Chollet für sein Buch <a href=\"https://www.manning.com/books/deep-learning-with-python\" class=\"external\">Deep Learning with Python</a> erstellt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyv_i85IWInT"
      },
      "outputs": [

      ],
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R81Wx8WP4c3G"
      },
      "source": [
        "Dieses Tutorial befasst sich nur mit **stündlichen Vorhersagen** . Beginnen Sie also damit, die Daten von 10-Minuten-Intervallen auf 1-Stunden-Intervalle zu subsampeln:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX6uGeeeWIkG"
      },
      "outputs": [

      ],
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "# Slice [start:stop:step], starting from index 5 take every 6th record.\n",
        "df = df[5::6]\n",
        "\n",
        "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdbOWXiTWM2T"
      },
      "source": [
        "Werfen wir einen Blick auf die Daten. Hier sind die ersten Zeilen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojHE-iCCWIhz"
      },
      "outputs": [

      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRzj1inMfgcO"
      },
      "source": [
        "Hier ist die Entwicklung einiger Funktionen im Laufe der Zeit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg5XIc5tfNlG"
      },
      "outputs": [

      ],
      "source": [
        "plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n",
        "plot_features = df[plot_cols]\n",
        "plot_features.index = date_time\n",
        "_ = plot_features.plot(subplots=True)\n",
        "\n",
        "plot_features = df[plot_cols][:480]\n",
        "plot_features.index = date_time[:480]\n",
        "_ = plot_features.plot(subplots=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXWLG0_WBhZS"
      },
      "source": [
        "### Inspizieren und reinigen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhmZXJew6GlS"
      },
      "source": [
        "Sehen Sie sich als Nächstes die Statistiken des Datensatzes an:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h510pgKVrrai"
      },
      "outputs": [

      ],
      "source": [
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzOTnWOoWMGK"
      },
      "source": [
        "#### Windgeschwindigkeit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i47LiW5DCVsP"
      },
      "source": [
        "Eine Sache, die auffallen sollte, ist der `min` Wert der Windgeschwindigkeitsspalte ( `wv (m/s)` ) und der maximale Wert ( `max. wv (m/s)` ). Diese `-9999` ist wahrscheinlich falsch.\n",
        "\n",
        "Es gibt eine separate Windrichtungsspalte, daher sollte die Geschwindigkeit größer als Null sein ( `>=0` ). Ersetzen Sie es durch Nullen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFOq0_80vF4d"
      },
      "outputs": [

      ],
      "source": [
        "wv = df['wv (m/s)']\n",
        "bad_wv = wv == -9999.0\n",
        "wv[bad_wv] = 0.0\n",
        "\n",
        "max_wv = df['max. wv (m/s)']\n",
        "bad_max_wv = max_wv == -9999.0\n",
        "max_wv[bad_max_wv] = 0.0\n",
        "\n",
        "# The above inplace edits are reflected in the DataFrame.\n",
        "df['wv (m/s)'].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtmu2IBPgPG8"
      },
      "source": [
        "### Feature-Engineering\n",
        "\n",
        "Bevor Sie mit dem Erstellen eines Modells beginnen, ist es wichtig, Ihre Daten zu verstehen und sicherzustellen, dass Sie die Modelldaten in angemessen formatierten Daten übergeben."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYyEaqiD6j4s"
      },
      "source": [
        "#### Wind\n",
        "\n",
        "Die letzte Spalte der Daten, `wd (deg)` – gibt die Windrichtung in Gradeinheiten an. Winkel sind keine guten Modelleingaben: 360° und 0° sollten nahe beieinander liegen und reibungslos umlaufen. Die Richtung sollte keine Rolle spielen, wenn der Wind nicht weht.\n",
        "\n",
        "Im Moment sieht die Verteilung der Winddaten so aus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO7JGTcWQG2z"
      },
      "outputs": [

      ],
      "source": [
        "plt.hist2d(df['wd (deg)'], df['wv (m/s)'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind Direction [deg]')\n",
        "plt.ylabel('Wind Velocity [m/s]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWnf5dwMU1_g"
      },
      "source": [
        "Dies ist jedoch für das Modell einfacher zu interpretieren, wenn Sie die Windrichtungs- und -geschwindigkeitsspalten in einen **Windvektor** umwandeln:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GmSTHXw6lI1"
      },
      "outputs": [

      ],
      "source": [
        "wv = df.pop('wv (m/s)')\n",
        "max_wv = df.pop('max. wv (m/s)')\n",
        "\n",
        "# Convert to radians.\n",
        "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
        "\n",
        "# Calculate the wind x and y components.\n",
        "df['Wx'] = wv*np.cos(wd_rad)\n",
        "df['Wy'] = wv*np.sin(wd_rad)\n",
        "\n",
        "# Calculate the max wind x and y components.\n",
        "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "df['max Wy'] = max_wv*np.sin(wd_rad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iI0zDoxWDyB"
      },
      "source": [
        "Die Verteilung der Windvektoren ist für das Modell viel einfacher richtig zu interpretieren:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMgCG5o2SYKD"
      },
      "outputs": [

      ],
      "source": [
        "plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind X [m/s]')\n",
        "plt.ylabel('Wind Y [m/s]')\n",
        "ax = plt.gca()\n",
        "ax.axis('tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8im1ttOWlRB"
      },
      "source": [
        "#### Zeit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YE21HKK40zQ"
      },
      "source": [
        "In ähnlicher Weise ist die Spalte `Date Time` sehr nützlich, jedoch nicht in dieser Zeichenfolgenform. Beginnen Sie damit, es in Sekunden umzuwandeln:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIFf-VjMfnh3"
      },
      "outputs": [

      ],
      "source": [
        "timestamp_s = date_time.map(pd.Timestamp.timestamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC_pnM1D5Sgc"
      },
      "source": [
        "Ähnlich wie die Windrichtung ist die Zeit in Sekunden keine nützliche Modelleingabe. Da es sich um Wetterdaten handelt, haben sie eine klare tägliche und jährliche Periodizität. Es gibt viele Möglichkeiten, wie Sie mit der Periodizität umgehen können.\n",
        "\n",
        "Sie können brauchbare Signale erhalten, indem Sie Sinus- und Kosinustransformationen verwenden, um die Signale \"Tageszeit\" und \"Jahreszeit\" zu löschen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBfX6CDwax73"
      },
      "outputs": [

      ],
      "source": [
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "\n",
        "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXBbTJZfuuTC"
      },
      "outputs": [

      ],
      "source": [
        "plt.plot(np.array(df['Day sin'])[:25])\n",
        "plt.plot(np.array(df['Day cos'])[:25])\n",
        "plt.xlabel('Time [h]')\n",
        "plt.title('Time of day signal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiurzTGQgf_D"
      },
      "source": [
        "Dadurch erhält das Modell Zugriff auf die wichtigsten Frequenzmerkmale. In diesem Fall wussten Sie vorher, welche Frequenzen wichtig sind.\n",
        "\n",
        "Wenn Sie diese Informationen nicht haben, können Sie bestimmen, welche Frequenzen wichtig sind, indem Sie Merkmale mit <a href=\"https://en.wikipedia.org/wiki/Fast_Fourier_transform\" class=\"external\">Fast Fourier Transform</a> extrahieren. Um die Annahmen zu überprüfen, hier das `tf.signal.rfft` der Temperatur über der Zeit. Beachten Sie die offensichtlichen Spitzen bei Frequenzen nahe `1/year` und `1/day` :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN4U1fcMiTYs"
      },
      "outputs": [

      ],
      "source": [
        "fft = tf.signal.rfft(df['T (degC)'])\n",
        "f_per_dataset = np.arange(0, len(fft))\n",
        "\n",
        "n_samples_h = len(df['T (degC)'])\n",
        "hours_per_year = 24*365.2524\n",
        "years_per_dataset = n_samples_h/(hours_per_year)\n",
        "\n",
        "f_per_year = f_per_dataset/years_per_dataset\n",
        "plt.step(f_per_year, np.abs(fft))\n",
        "plt.xscale('log')\n",
        "plt.ylim(0, 400000)\n",
        "plt.xlim([0.1, max(plt.xlim())])\n",
        "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n",
        "_ = plt.xlabel('Frequency (log scale)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rbL8bSGDHy3"
      },
      "source": [
        "### Teilen Sie die Daten auf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoFJZmXBaxCc"
      },
      "source": [
        "Sie verwenden eine Aufteilung `(70%, 20%, 10%)` für die Trainings-, Validierungs- und Testdatensätze. Beachten Sie, dass die Daten vor dem Teilen **nicht** zufällig gemischt werden. Dies aus zwei Gründen:\n",
        "\n",
        "1. Es stellt sicher, dass das Zerhacken der Daten in Fenster aufeinanderfolgender Abtastungen weiterhin möglich ist.\n",
        "2. Es stellt sicher, dass die Validierungs-/Testergebnisse realistischer sind, da sie anhand der Daten ausgewertet werden, die nach dem Trainieren des Modells gesammelt wurden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia-MPAHxbInX"
      },
      "outputs": [

      ],
      "source": [
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "n = len(df)\n",
        "train_df = df[0:int(n*0.7)]\n",
        "val_df = df[int(n*0.7):int(n*0.9)]\n",
        "test_df = df[int(n*0.9):]\n",
        "\n",
        "num_features = df.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eFckdUUHWmT"
      },
      "source": [
        "### Normalisieren Sie die Daten\n",
        "\n",
        "Es ist wichtig, Merkmale zu skalieren, bevor ein neuronales Netzwerk trainiert wird. Normalisierung ist eine gängige Methode, um diese Skalierung durchzuführen: Subtrahieren Sie den Mittelwert und dividieren Sie ihn durch die Standardabweichung jedes Merkmals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxbIic5TMlxx"
      },
      "source": [
        "Der Mittelwert und die Standardabweichung sollten nur anhand der Trainingsdaten berechnet werden, damit die Modelle keinen Zugriff auf die Werte in den Validierungs- und Testsätzen haben.\n",
        "\n",
        "Es kann auch argumentiert werden, dass das Modell beim Training keinen Zugriff auf zukünftige Werte im Trainingssatz haben sollte und dass diese Normalisierung mithilfe von gleitenden Durchschnitten erfolgen sollte. Das ist nicht der Schwerpunkt dieses Tutorials, und die Validierungs- und Testsets stellen sicher, dass Sie (etwas) ehrliche Metriken erhalten. Aus Gründen der Einfachheit verwendet dieses Tutorial daher einen einfachen Durchschnitt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eji6njXvHusN"
      },
      "outputs": [

      ],
      "source": [
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6ufs8kk9JQw"
      },
      "source": [
        "Schauen Sie sich nun die Verteilung der Funktionen an. Einige Merkmale haben zwar lange Ausläufer, aber es gibt keine offensichtlichen Fehler wie den Windgeschwindigkeitswert von `-9999` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0UYEnkwm8Fe"
      },
      "outputs": [

      ],
      "source": [
        "df_std = (df - train_mean) / train_std\n",
        "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
        "_ = ax.set_xticklabels(df.keys(), rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBBmdxZ2HgfJ"
      },
      "source": [
        "## Datenfensterung\n",
        "\n",
        "Die Modelle in diesem Lernprogramm erstellen eine Reihe von Vorhersagen basierend auf einem Fenster aufeinanderfolgender Stichproben aus den Daten.\n",
        "\n",
        "Die Hauptmerkmale der Eingabefenster sind:\n",
        "\n",
        "- Die Breite (Anzahl der Zeitschritte) der Eingabe- und Beschriftungsfenster.\n",
        "- Der Zeitversatz zwischen ihnen.\n",
        "- Welche Features werden als Eingaben, Labels oder beides verwendet?\n",
        "\n",
        "Dieses Tutorial erstellt eine Vielzahl von Modellen (einschließlich linearer, DNN-, CNN- und RNN-Modelle) und verwendet sie für beide:\n",
        "\n",
        "- *Single-Output-* und *Multi-Output-* Vorhersagen.\n",
        "- Vorhersagen für *einzelne Zeitschritte* und *mehrere Zeitschritte* .\n",
        "\n",
        "Dieser Abschnitt konzentriert sich auf die Implementierung des Datenfensters, sodass es für alle diese Modelle wiederverwendet werden kann.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAhGUVx1jtOy"
      },
      "source": [
        "Je nach Aufgabenstellung und Modelltyp möchten Sie vielleicht unterschiedliche Datenfenster generieren. Hier sind einige Beispiele:\n",
        "\n",
        "1. Um beispielsweise eine einzelne Vorhersage 24 Stunden in die Zukunft zu treffen, könnten Sie bei einem 24-Stunden-Verlauf ein Fenster wie das folgende definieren:\n",
        "\n",
        "![Eine Vorhersage 24 Stunden in die Zukunft.](images/raw_window_24h.png)\n",
        "\n",
        "1. Ein Modell, das bei sechs Stunden Historie eine Vorhersage eine Stunde in die Zukunft macht, würde ein Fenster wie dieses benötigen:\n",
        "\n",
        "![Eine Vorhersage eine Stunde in die Zukunft.](images/raw_window_1h.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa2BbfNZt8wy"
      },
      "source": [
        "Der Rest dieses Abschnitts definiert eine `WindowGenerator` -Klasse. Diese Klasse kann:\n",
        "\n",
        "1. Behandeln Sie die Indizes und Offsets wie in den Diagrammen oben gezeigt.\n",
        "2. Aufteilen von Feature-Fenstern in `(features, labels)` Paare.\n",
        "3. Plotten Sie den Inhalt der resultierenden Fenster.\n",
        "4. Generieren Sie mithilfe von `tf.data.Dataset` s effizient Batches dieser Fenster aus den Trainings-, Bewertungs- und Testdaten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfx3jGjyziUF"
      },
      "source": [
        "### 1. Indizes und Offsets\n",
        "\n",
        "Beginnen Sie mit dem Erstellen der `WindowGenerator` -Klasse. Die Methode `__init__` enthält die gesamte notwendige Logik für die Eingabe- und Label-Indizes.\n",
        "\n",
        "Es verwendet auch die Trainings-, Bewertungs- und Test-DataFrames als Eingabe. Diese werden später in `tf.data.Dataset` von Windows konvertiert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kem30j8QHxyW"
      },
      "outputs": [

      ],
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVJgblsYzL1g"
      },
      "source": [
        "Hier ist der Code zum Erstellen der 2 Fenster, die in den Diagrammen am Anfang dieses Abschnitts gezeigt werden:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsM5kRkz0UwK"
      },
      "outputs": [

      ],
      "source": [
        "w1 = WindowGenerator(input_width=24, label_width=1, shift=24,\n",
        "                     label_columns=['T (degC)'])\n",
        "w1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viwKsYeAKFUn"
      },
      "outputs": [

      ],
      "source": [
        "w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n",
        "                     label_columns=['T (degC)'])\n",
        "w2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJaUyTWQJd-L"
      },
      "source": [
        "### 2. Teilen\n",
        "\n",
        "Bei einer gegebenen Liste aufeinanderfolgender Eingaben konvertiert die Methode `split_window` diese in ein Fenster mit Eingaben und ein Fenster mit Bezeichnungen.\n",
        "\n",
        "Das zuvor definierte Beispiel `w2` wird wie folgt aufgeteilt:\n",
        "\n",
        "![Das anfängliche Fenster enthält alle aufeinanderfolgenden Samples, dies teilt es in Paare (Eingänge, Labels) auf](images/split_window.png)\n",
        "\n",
        "Dieses Diagramm zeigt nicht die `features` der Daten, aber diese `split_window` Funktion verarbeitet auch die `label_columns` , sodass sie sowohl für die Einzelausgabe- als auch für die Mehrfachausgabebeispiele verwendet werden kann."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4KbxfzqkXPW"
      },
      "outputs": [

      ],
      "source": [
        "def split_window(self, features):\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes\n",
        "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6U6VtVuM15s"
      },
      "source": [
        "Versuch es:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeCWbq6KLmL7"
      },
      "outputs": [

      ],
      "source": [
        "# Stack three slices, the length of the total window.\n",
        "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
        "                           np.array(train_df[100:100+w2.total_window_size]),\n",
        "                           np.array(train_df[200:200+w2.total_window_size])])\n",
        "\n",
        "example_inputs, example_labels = w2.split_window(example_window)\n",
        "\n",
        "print('All shapes are: (batch, time, features)')\n",
        "print(f'Window shape: {example_window.shape}')\n",
        "print(f'Inputs shape: {example_inputs.shape}')\n",
        "print(f'Labels shape: {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtMk1ffk2Mmd"
      },
      "source": [
        "Typischerweise werden Daten in TensorFlow in Arrays gepackt, wobei sich der äußerste Index über Beispiele erstreckt (die „Batch“-Dimension). Die mittleren Indizes sind die Dimension(en) \"Zeit\" oder \"Raum\" (Breite, Höhe). Die innersten Indizes sind die Merkmale.\n",
        "\n",
        "Der obige Code nahm einen Stapel von drei 7-Zeitschrittfenstern mit 19 Merkmalen bei jedem Zeitschritt. Es teilt sie in einen Stapel von 6-mal Schritt 19-Feature-Eingaben und ein 1-mal Schritt 1-Feature-Label auf. Das Label hat nur eine Eigenschaft, da der `WindowGenerator` mit `label_columns=['T (degC)']` initialisiert wurde. Zunächst werden in diesem Lernprogramm Modelle erstellt, die einzelne Ausgabebezeichnungen vorhersagen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFZukGXrJoGo"
      },
      "source": [
        "### 3. Grundstück\n",
        "\n",
        "Hier ist eine Plot-Methode, die eine einfache Visualisierung des geteilten Fensters ermöglicht:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmgd1qkYUWT7"
      },
      "outputs": [

      ],
      "source": [
        "w2.example = example_inputs, example_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIrYccI-Hm3B"
      },
      "outputs": [

      ],
      "source": [
        "def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(max_n, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='X', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('Time [h]')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXvctEuK68vX"
      },
      "source": [
        "Dieses Diagramm richtet Eingaben, Beschriftungen und (spätere) Vorhersagen basierend auf der Zeit aus, auf die sich das Element bezieht:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjTqUnglOOni"
      },
      "outputs": [

      ],
      "source": [
        "w2.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqiqcPOldPG6"
      },
      "source": [
        "Sie können die anderen Spalten zeichnen, aber das Beispielfenster `w2` Konfiguration hat nur Beschriftungen für die Spalte `T (degC)` ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBRe4wnlfCH8"
      },
      "outputs": [

      ],
      "source": [
        "w2.plot(plot_col='p (mbar)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCvD-UaUzYMw"
      },
      "source": [
        "### 4. Erstellen Sie `tf.data.Dataset` s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLO3SFR9Osdf"
      },
      "source": [
        "Schließlich nimmt diese `make_dataset` Methode einen Zeitreihen-DataFrame und konvertiert ihn mithilfe der `tf.keras.utils.timeseries_dataset_from_array` Funktion in ein `tf.data.Dataset` von `(input_window, label_window)` -Paaren:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35qoSQeRVfJg"
      },
      "outputs": [

      ],
      "source": [
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=32,)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvsxQwJaCift"
      },
      "source": [
        "Das `WindowGenerator` Objekt enthält Trainings-, Validierungs- und Testdaten.\n",
        "\n",
        "Fügen Sie Eigenschaften für den Zugriff auf sie als `tf.data.Dataset` s hinzu, indem Sie die zuvor definierte Methode `make_dataset` verwenden. Fügen Sie außerdem einen Standard-Beispielstapel für einfachen Zugriff und Plotten hinzu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jZ2KkqGCfzu"
      },
      "outputs": [

      ],
      "source": [
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF_Vj6Iw3Y2w"
      },
      "source": [
        "Jetzt gibt Ihnen das `WindowGenerator` Objekt Zugriff auf die `tf.data.Dataset` Objekte, sodass Sie die Daten einfach durchlaufen können.\n",
        "\n",
        "Die Eigenschaft `Dataset.element_spec` teilt Ihnen die Struktur, Datentypen und Formen der Datensatzelemente mit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daJ0-U383YVs"
      },
      "outputs": [

      ],
      "source": [
        "# Each element is an (inputs, label) pair.\n",
        "w2.train.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKTx3_Z7ua-n"
      },
      "source": [
        "Das Iterieren über einen `Dataset` ergibt konkrete Batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gtKXEgf4Iml"
      },
      "outputs": [

      ],
      "source": [
        "for example_inputs, example_labels in w2.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyuGuJUgjUK3"
      },
      "source": [
        "## Einstufige Modelle\n",
        "\n",
        "Das einfachste Modell, das Sie auf dieser Art von Daten aufbauen können, ist eines, das den Wert einer einzelnen Funktion vorhersagt – 1 Zeitschritt (eine Stunde) in die Zukunft, basierend nur auf den aktuellen Bedingungen.\n",
        "\n",
        "Beginnen Sie also damit, Modelle zu erstellen, um den `T (degC)` -Wert eine Stunde in die Zukunft vorherzusagen.\n",
        "\n",
        "![Sagen Sie den nächsten Zeitschritt voraus](images/narrow_window.png)\n",
        "\n",
        "Konfigurieren Sie ein `WindowGenerator` -Objekt, um diese Single-Step-Paare `(input, label)` zu erzeugen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5QX1G1JTPCr"
      },
      "outputs": [

      ],
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    input_width=1, label_width=1, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "single_step_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKTm8ajVGw4N"
      },
      "source": [
        "Das `window` erstellt `tf.data.Dataset` s aus den Trainings-, Validierungs- und Testdatensätzen, sodass Sie problemlos Datenstapel durchlaufen können.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do4ILUaBF8oc"
      },
      "outputs": [

      ],
      "source": [
        "for example_inputs, example_labels in single_step_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1bbPiR3VAm_"
      },
      "source": [
        "### Grundlinie\n",
        "\n",
        "Vor dem Bau eines trainierbaren Modells wäre es gut, eine Leistungsbaseline als Vergleichspunkt mit den später komplizierteren Modellen zu haben.\n",
        "\n",
        "Diese erste Aufgabe besteht darin, die Temperatur eine Stunde in die Zukunft vorherzusagen, wenn der aktuelle Wert aller Merkmale gegeben ist. Die aktuellen Werte beinhalten die aktuelle Temperatur.\n",
        "\n",
        "Beginnen Sie also mit einem Modell, das nur die aktuelle Temperatur als Vorhersage zurückgibt und „keine Änderung“ vorhersagt. Dies ist eine vernünftige Grundlinie, da sich die Temperatur langsam ändert. Natürlich wird diese Baseline weniger gut funktionieren, wenn Sie eine Vorhersage in der Zukunft treffen.\n",
        "\n",
        "![Senden Sie die Eingabe an die Ausgabe](images/baseline.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TybQaIsi3yg"
      },
      "outputs": [

      ],
      "source": [
        "class Baseline(tf.keras.Model):\n",
        "  def __init__(self, label_index=None):\n",
        "    super().__init__()\n",
        "    self.label_index = label_index\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.label_index is None:\n",
        "      return inputs\n",
        "    result = inputs[:, :, self.label_index]\n",
        "    return result[:, :, tf.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vb3f948i8p8"
      },
      "source": [
        "Instanziieren und bewerten Sie dieses Modell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS3-QKc4sX0D"
      },
      "outputs": [

      ],
      "source": [
        "baseline = Baseline(label_index=column_indices['T (degC)'])\n",
        "\n",
        "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhBxQcCSs7Ec"
      },
      "source": [
        "Das hat einige Leistungsmetriken gedruckt, aber diese geben Ihnen kein Gefühl dafür, wie gut das Modell abschneidet.\n",
        "\n",
        "Der `WindowGenerator` hat eine Plot-Methode, aber die Plots werden mit nur einem einzigen Sample nicht sehr interessant sein.\n",
        "\n",
        "Erstellen Sie also einen breiteren `WindowGenerator` , der Fenster 24 Stunden lang aufeinanderfolgende Eingaben und Beschriftungen gleichzeitig generiert. Die neue Variable `wide_window` ändert nichts an der Funktionsweise des Modells. Das Modell macht immer noch Vorhersagen eine Stunde in die Zukunft basierend auf einem einzelnen Eingabezeitschritt. Hier verhält sich die `time` wie die `batch` : Jede Vorhersage wird unabhängig gemacht, ohne Wechselwirkung zwischen den Zeitschritten:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8jNR5uuJ5Zp"
      },
      "outputs": [

      ],
      "source": [
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "wide_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAnj7CFZkuYv"
      },
      "source": [
        "Dieses erweiterte Fenster kann ohne Codeänderungen direkt an dasselbe `baseline` übergeben werden. Dies ist möglich, weil die Eingaben und Beschriftungen die gleiche Anzahl von Zeitschritten haben und die Basislinie die Eingabe nur an die Ausgabe weiterleitet:\n",
        "\n",
        "![Eine Vorhersage 1 Stunde in die Zukunft, jede Stunde.](images/last_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGKdvdg087qs"
      },
      "outputs": [

      ],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', baseline(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqQHX1K0JW-"
      },
      "source": [
        "Beachten Sie beim Zeichnen der Vorhersagen des Basismodells, dass es sich lediglich um die um eine Stunde nach rechts verschobenen Beschriftungen handelt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQyAPVLgWTOZ"
      },
      "outputs": [

      ],
      "source": [
        "wide_window.plot(baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e93TLUhfAVg2"
      },
      "source": [
        "In den obigen Diagrammen von drei Beispielen wird das Einzelschrittmodell über einen Zeitraum von 24 Stunden ausgeführt. Dies verdient eine Erklärung:\n",
        "\n",
        "- Die blaue `Inputs` zeigt die Eingangstemperatur bei jedem Zeitschritt. Das Modell erhält alle Funktionen, dieser Plot zeigt nur die Temperatur.\n",
        "- Die grünen `Labels` zeigen den Zielvorhersagewert. Diese Punkte werden zur Vorhersagezeit angezeigt, nicht zur Eingabezeit. Aus diesem Grund wird der Bereich der Labels relativ zu den Eingängen um 1 Schritt verschoben.\n",
        "- Die orangefarbenen `Predictions` sind die Vorhersagen des Modells für jeden Ausgabezeitschritt. Wenn das Modell perfekte Vorhersagen machen würde, würden die Vorhersagen direkt auf den `Labels` landen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4aOJScj52Yu"
      },
      "source": [
        "### Lineares Modell\n",
        "\n",
        "Das einfachste **trainierbare** Modell, das Sie auf diese Aufgabe anwenden können, besteht darin, eine lineare Transformation zwischen Eingabe und Ausgabe einzufügen. In diesem Fall hängt die Ausgabe eines Zeitschritts nur von diesem Schritt ab:\n",
        "\n",
        "![Eine Einzelschrittvorhersage](images/narrow_window.png)\n",
        "\n",
        "Ein `tf.keras.layers.Dense` Layer ohne `activation` ist ein lineares Modell. Die Ebene transformiert nur die letzte Achse der Daten von `(batch, time, inputs)` in `(batch, time, units)` ; es wird unabhängig auf jeden Artikel über die `batch` und `time` angewendet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6341OXuQ5xA9"
      },
      "outputs": [

      ],
      "source": [
        "linear = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwaOM8RucUSn"
      },
      "outputs": [

      ],
      "source": [
        "print('Input shape:', single_step_window.example[0].shape)\n",
        "print('Output shape:', linear(single_step_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMZTYIj3bYLg"
      },
      "source": [
        "Dieses Tutorial trainiert viele Modelle, packen Sie also das Trainingsverfahren in eine Funktion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbCL6VIrk-Gt"
      },
      "outputs": [

      ],
      "source": [
        "MAX_EPOCHS = 20\n",
        "\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OobVjM-schwj"
      },
      "source": [
        "Trainieren Sie das Modell und bewerten Sie seine Leistung:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9agbz2qB9bLS"
      },
      "outputs": [

      ],
      "source": [
        "history = compile_and_fit(linear, single_step_window)\n",
        "\n",
        "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
        "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U9XukYh8beN"
      },
      "source": [
        "Wie das `baseline` kann das lineare Modell für Stapel von breiten Fenstern aufgerufen werden. Auf diese Weise verwendet, erstellt das Modell eine Reihe unabhängiger Vorhersagen für aufeinanderfolgende Zeitschritte. Die `time` verhält sich wie eine weitere `batch` . Es gibt keine Wechselwirkungen zwischen den Vorhersagen bei jedem Zeitschritt.\n",
        "\n",
        "![Eine Einzelschrittvorhersage](images/wide_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9UVM5Sw9KQN"
      },
      "outputs": [

      ],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', baseline(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-CGj85oKaOG"
      },
      "source": [
        "Hier ist die Darstellung der Beispielvorhersagen für `wide_window` . Beachten Sie, dass die Vorhersage in vielen Fällen eindeutig besser ist als nur die Eingabetemperatur zurückzugeben, aber in einigen Fällen schlechter ist:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCC8VVo-OvwV"
      },
      "outputs": [

      ],
      "source": [
        "wide_window.plot(linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is51vU8EMl6c"
      },
      "source": [
        "Ein Vorteil linearer Modelle besteht darin, dass sie relativ einfach zu interpretieren sind. Sie können die Gewichte der Ebene herausziehen und das jeder Eingabe zugewiesene Gewicht visualisieren:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4uCTbsmK8VI"
      },
      "outputs": [

      ],
      "source": [
        "plt.bar(x = range(len(train_df.columns)),\n",
        "        height=linear.layers[0].kernel[:,0].numpy())\n",
        "axis = plt.gca()\n",
        "axis.set_xticks(range(len(train_df.columns)))\n",
        "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylng7215boIY"
      },
      "source": [
        "Manchmal legt das Modell nicht einmal das größte Gewicht auf die Eingabe `T (degC)` . Dies ist eines der Risiken der zufälligen Initialisierung. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W18e6da1cNbw"
      },
      "source": [
        "### Dicht\n",
        "\n",
        "Bevor Sie Modelle anwenden, die tatsächlich mit mehreren Zeitschritten arbeiten, sollten Sie die Leistung von tieferen, leistungsfähigeren Modellen mit einzelnen Eingabeschritten überprüfen.\n",
        "\n",
        "Hier ist ein Modell, das dem `linear` Modell ähnlich ist, außer dass es mehrere `Dense` Schichten zwischen der Eingabe und der Ausgabe stapelt: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z86WkYp7cNAD"
      },
      "outputs": [

      ],
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5dv_whJdswH"
      },
      "source": [
        "### Mehrstufig dicht\n",
        "\n",
        "Ein Einzelzeitschrittmodell hat keinen Kontext für die aktuellen Werte seiner Eingaben. Es kann nicht sehen, wie sich die Eingabefunktionen im Laufe der Zeit ändern. Um dieses Problem zu lösen, benötigt das Modell Zugriff auf mehrere Zeitschritte, wenn Vorhersagen getroffen werden:\n",
        "\n",
        "![Für jede Vorhersage werden drei Zeitschritte verwendet.](images/conv_window.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zac-ti8agbJ7"
      },
      "source": [
        "Die `baseline` , `linear` und `dense` Modelle behandelten jeden Zeitschritt unabhängig. Hier benötigt das Modell mehrere Zeitschritte als Eingabe, um eine einzelne Ausgabe zu erzeugen.\n",
        "\n",
        "Erstellen Sie einen `WindowGenerator` , der Stapel von dreistündigen Eingaben und einstündigen Labels erzeugt:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtN4BwZ37niR"
      },
      "source": [
        "Beachten Sie, dass der `shift` von `Window` relativ zum Ende der beiden Fenster ist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBh0j5djUKY2"
      },
      "outputs": [

      ],
      "source": [
        "CONV_WIDTH = 3\n",
        "conv_window = WindowGenerator(\n",
        "    input_width=CONV_WIDTH,\n",
        "    label_width=1,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "conv_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCQ5gvs68Xkd"
      },
      "outputs": [

      ],
      "source": [
        "conv_window.plot()\n",
        "plt.title(\"Given 3 hours of inputs, predict 1 hour into the future.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We0HdMxKeqB_"
      },
      "source": [
        "Sie könnten ein `dense` Modell in einem Fenster mit mehreren Eingabeschritten trainieren, indem `tf.keras.layers.Flatten` als erste Ebene des Modells hinzufügen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNQnUOkOnC1G"
      },
      "outputs": [

      ],
      "source": [
        "multi_step_dense = tf.keras.Sequential([\n",
        "    # Shape: (time, features) => (time*features)\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "    # Add back the time dimension.\n",
        "    # Shape: (outputs) => (1, outputs)\n",
        "    tf.keras.layers.Reshape([1, -1]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cayD74luo4Vq"
      },
      "outputs": [

      ],
      "source": [
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', multi_step_dense(conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu91yEbRo9-J"
      },
      "outputs": [

      ],
      "source": [
        "history = compile_and_fit(multi_step_dense, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val)\n",
        "performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnqdXYT6pkEh"
      },
      "outputs": [

      ],
      "source": [
        "conv_window.plot(multi_step_dense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWfrsP8mq8lV"
      },
      "source": [
        "Der Hauptnachteil dieses Ansatzes besteht darin, dass das resultierende Modell nur auf Eingabefenstern mit genau dieser Form ausgeführt werden kann. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-q6tz5Yq8Jk"
      },
      "outputs": [

      ],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "try:\n",
        "  print('Output shape:', multi_step_dense(wide_window.example[0]).shape)\n",
        "except Exception as e:\n",
        "  print(f'\\n{type(e).__name__}:{e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvvajm3ip_8V"
      },
      "source": [
        "Die Faltungsmodelle im nächsten Abschnitt beheben dieses Problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrpU6gwSJome"
      },
      "source": [
        "### Neuronales Faltungsnetzwerk\n",
        "\n",
        "Eine Faltungsschicht ( `tf.keras.layers.Conv1D` ) verwendet ebenfalls mehrere Zeitschritte als Eingabe für jede Vorhersage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdLBwoaHmsWb"
      },
      "source": [
        "Unten ist **dasselbe** Modell wie `multi_step_dense` , neu geschrieben mit einer Faltung.\n",
        "\n",
        "Beachten Sie die Änderungen:\n",
        "\n",
        "- Die `tf.keras.layers.Flatten` und die erste `tf.keras.layers.Dense` werden durch eine `tf.keras.layers.Conv1D` ersetzt.\n",
        "- Das `tf.keras.layers.Reshape` ist nicht mehr notwendig, da die Faltung die Zeitachse in ihrer Ausgabe behält."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5azaMBj4ac9t"
      },
      "outputs": [

      ],
      "source": [
        "conv_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32,\n",
        "                           kernel_size=(CONV_WIDTH,),\n",
        "                           activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftaH6B5ECRiK"
      },
      "source": [
        "Führen Sie es in einem Beispielstapel aus, um zu überprüfen, ob das Modell Ausgaben mit der erwarteten Form erzeugt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YNgt1-e98lH"
      },
      "outputs": [

      ],
      "source": [
        "print(\"Conv model on `conv_window`\")\n",
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', conv_model(conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m4kC-jGCY3x"
      },
      "source": [
        "Trainieren und bewerten Sie es im `conv_window` und es sollte eine ähnliche Leistung wie das `multi_step_dense` Modell erbringen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDVWdm4paUW7"
      },
      "outputs": [

      ],
      "source": [
        "history = compile_and_fit(conv_model, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Conv'] = conv_model.evaluate(conv_window.val)\n",
        "performance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYRipDeXs0Kr"
      },
      "source": [
        "Der Unterschied zwischen diesem `conv_model` und dem `multi_step_dense` Modell besteht darin, dass das `conv_model` mit Eingaben beliebiger Länge ausgeführt werden kann. Die Faltungsschicht wird auf ein gleitendes Eingabefenster angewendet:\n",
        "\n",
        "![Ausführen eines Faltungsmodells auf einer Sequenz](images/wide_conv_window.png)\n",
        "\n",
        "Wenn Sie es mit einer breiteren Eingabe ausführen, wird eine breitere Ausgabe erzeugt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoqccxx9r5jF"
      },
      "outputs": [

      ],
      "source": [
        "print(\"Wide window\")\n",
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Labels shape:', wide_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_WGxtLIHhRF"
      },
      "source": [
        "Beachten Sie, dass die Ausgabe kürzer als die Eingabe ist. Damit das Training oder Plotten funktioniert, müssen die Beschriftungen und die Vorhersage dieselbe Länge haben. Erstellen Sie also einen `WindowGenerator` , um breite Fenster mit ein paar zusätzlichen Eingabezeitschritten zu erzeugen, damit die Label- und Vorhersagelängen übereinstimmen: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VPvJ_VwTc0f"
      },
      "outputs": [

      ],
      "source": [
        "LABEL_WIDTH = 24\n",
        "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
        "wide_conv_window = WindowGenerator(\n",
        "    input_width=INPUT_WIDTH,\n",
        "    label_width=LABEL_WIDTH,\n",
        "    shift=1,\n",
        "    label_columns=['T (degC)'])\n",
        "\n",
        "wide_conv_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtqlWYXeKXej"
      },
      "outputs": [

      ],
      "source": [
        "print(\"Wide conv window\")\n",
        "print('Input shape:', wide_conv_window.example[0].shape)\n",
        "print('Labels shape:', wide_conv_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_conv_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzxbbS56cSBV"
      },
      "source": [
        "Jetzt können Sie die Vorhersagen des Modells in einem breiteren Fenster darstellen. Beachten Sie die 3 Eingabezeitschritte vor der ersten Vorhersage. Jede Vorhersage hier basiert auf den 3 vorangegangenen Zeitschritten:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR7VyL45UuEe"
      },
      "outputs": [

      ],
      "source": [
        "wide_conv_window.plot(conv_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "### Wiederkehrendes neuronales Netzwerk\n",
        "\n",
        "Ein Recurrent Neural Network (RNN) ist eine Art von neuronalem Netzwerk, das sich gut für Zeitreihendaten eignet. RNNs verarbeiten eine Zeitreihe Schritt für Schritt und behalten einen internen Zustand von Zeitschritt zu Zeitschritt bei.\n",
        "\n",
        "Weitere Informationen finden Sie im Tutorial [Textgenerierung mit einem RNN](https://www.tensorflow.org/text/tutorials/text_generation) und im Leitfaden [Recurrent Neural Networks (RNN) with Keras](https://www.tensorflow.org/guide/keras/rnn) .\n",
        "\n",
        "In diesem Lernprogramm verwenden Sie eine RNN-Schicht namens Long Short-Term Memory ( `tf.keras.layers.LSTM` )."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfQbHSMb1ATa"
      },
      "source": [
        "Ein wichtiges Konstruktorargument für alle Keras-RNN-Layer, wie z. B. `tf.keras.layers.LSTM` , ist das Argument `return_sequences` . Diese Einstellung kann den Layer auf zwei Arten konfigurieren:\n",
        "\n",
        "1. Bei `False` , dem Standardwert, gibt die Ebene nur die Ausgabe des letzten Zeitschritts zurück, sodass das Modell Zeit hat, seinen internen Zustand aufzuwärmen, bevor es eine einzelne Vorhersage trifft:\n",
        "\n",
        "![Ein LSTM, das sich aufwärmt und eine einzige Vorhersage macht](images/lstm_1_window.png)\n",
        "\n",
        "1. Wenn `True` , gibt der Layer eine Ausgabe für jede Eingabe zurück. Dies ist nützlich für:\n",
        "    - Stapeln von RNN-Schichten.\n",
        "    - Trainieren eines Modells in mehreren Zeitschritten gleichzeitig.\n",
        "\n",
        "![Ein LSTM, das nach jedem Zeitschritt eine Vorhersage macht](images/lstm_many_window.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXKLCJy8nWNU"
      },
      "outputs": [

      ],
      "source": [
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F124B00KZcLC"
      },
      "source": [
        "Mit `return_sequences=True` kann das Modell mit 24 Stunden Daten gleichzeitig trainiert werden.\n",
        "\n",
        "Hinweis: Dies gibt einen pessimistischen Überblick über die Leistung des Modells. Beim ersten Zeitschritt hat das Modell keinen Zugriff auf vorherige Schritte und kann daher nicht besser abschneiden als die zuvor gezeigten einfachen `linear` und `dense` Modelle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZEROCQVYV6q"
      },
      "outputs": [

      ],
      "source": [
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', lstm_model(wide_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvdWRl1e9WJl"
      },
      "outputs": [

      ],
      "source": [
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwAOWCVgB26e"
      },
      "outputs": [

      ],
      "source": [
        "wide_window.plot(lstm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYglOCKehi8F"
      },
      "source": [
        "### Leistung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pCk0_rwhi8H"
      },
      "source": [
        "Mit diesem Datensatz schneidet typischerweise jedes der Modelle etwas besser ab als das davor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjEkt488hi8I"
      },
      "outputs": [

      ],
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.ylabel('mean_absolute_error [T (degC), normalized]')\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBMCpsdphi8L"
      },
      "outputs": [

      ],
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:12s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5rUJ_2YMWzG"
      },
      "source": [
        "### Modelle mit mehreren Ausgängen\n",
        "\n",
        "Die Modelle haben bisher alle ein einzelnes Ausgabemerkmal `T (degC)` für einen einzelnen Zeitschritt vorhergesagt.\n",
        "\n",
        "Alle diese Modelle können konvertiert werden, um mehrere Features vorherzusagen, indem Sie einfach die Anzahl der Einheiten in der Ausgabeschicht ändern und die Trainingsfenster so anpassen, dass alle Features in den `labels` enthalten sind ( `example_labels` ):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gk0Z91xjOwv"
      },
      "outputs": [

      ],
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    # `WindowGenerator` returns all features as labels if you \n",
        "    # don't set the `label_columns` argument.\n",
        "    input_width=1, label_width=1, shift=1)\n",
        "\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "for example_inputs, example_labels in wide_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmcjHfDskX1N"
      },
      "source": [
        "Beachten Sie oben, dass die `features` -Achse der Beschriftungen jetzt die gleiche Tiefe wie die Eingaben hat, anstatt `1` ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k7S5IHNhSNF"
      },
      "source": [
        "#### Grundlinie\n",
        "\n",
        "Dasselbe Basismodell ( `Baseline` ) kann hier verwendet werden, aber dieses Mal werden alle Funktionen wiederholt, anstatt einen bestimmten `label_index` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqqB9W-pjr5i"
      },
      "outputs": [

      ],
      "source": [
        "baseline = Baseline()\n",
        "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.metrics.MeanAbsoluteError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltQdgaqQjQWu"
      },
      "outputs": [

      ],
      "source": [
        "val_performance = {}\n",
        "performance = {}\n",
        "val_performance['Baseline'] = baseline.evaluate(wide_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(wide_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfbCrf5q3P6n"
      },
      "source": [
        "#### Dicht"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdpzH1dYjdIN"
      },
      "outputs": [

      ],
      "source": [
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uHuU9Cd3PTo"
      },
      "outputs": [

      ],
      "source": [
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsc9pur_mHsx"
      },
      "source": [
        "#### RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QbGLMyomXaz"
      },
      "outputs": [

      ],
      "source": [
        "%%time\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=24, label_width=24, shift=1)\n",
        "\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=num_features)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate( wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0)\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwhY2f_Nn0_K"
      },
      "source": [
        "<a id=\"residual\"></a>\n",
        "\n",
        "#### Erweitert: Restverbindungen\n",
        "\n",
        "Das `Baseline` -Modell von früher nutzte die Tatsache, dass sich die Sequenz von Zeitschritt zu Zeitschritt nicht drastisch ändert. Jedes bisher in diesem Tutorial trainierte Modell wurde zufällig initialisiert und musste dann lernen, dass die Ausgabe eine kleine Änderung gegenüber dem vorherigen Zeitschritt ist.\n",
        "\n",
        "Während Sie dieses Problem durch sorgfältige Initialisierung umgehen können, ist es einfacher, dies in die Modellstruktur zu integrieren.\n",
        "\n",
        "In der Zeitreihenanalyse ist es üblich, Modelle zu erstellen, die statt den nächsten Wert vorherzusagen, vorhersagen, wie sich der Wert im nächsten Zeitschritt ändern wird. In ähnlicher Weise beziehen sich Restnetzwerke – oder <a href=\"https://arxiv.org/abs/1512.03385\" class=\"external\">ResNets</a> – im Deep Learning auf Architekturen, bei denen jede Schicht zum akkumulierten Ergebnis des Modells beiträgt.\n",
        "\n",
        "So nutzen Sie das Wissen, dass die Änderung gering sein sollte.\n",
        "\n",
        "![Ein Modell mit einer Restverbindung](images/residual.png)\n",
        "\n",
        "Im Wesentlichen initialisiert dies das Modell so, dass es mit der `Baseline` übereinstimmt. Für diese Aufgabe hilft es Modellen, schneller zu konvergieren, mit etwas besserer Leistung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP58A_ORx0kM"
      },
      "source": [
        "Dieser Ansatz kann in Verbindung mit jedem in diesem Lernprogramm besprochenen Modell verwendet werden.\n",
        "\n",
        "Hier wird es auf das LSTM-Modell angewendet, beachten Sie die Verwendung von `tf.initializers.zeros` , um sicherzustellen, dass die anfänglich vorhergesagten Änderungen gering sind und die verbleibende Verbindung nicht überwältigen. Hier gibt es keine symmetriebrechenden Bedenken für die Gradienten, da die `zeros` nur auf der letzten Ebene verwendet werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YlfnDQC22TQ"
      },
      "outputs": [

      ],
      "source": [
        "class ResidualWrapper(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def call(self, inputs, *args, **kwargs):\n",
        "    delta = self.model(inputs, *args, **kwargs)\n",
        "\n",
        "    # The prediction for each time step is the input\n",
        "    # from the previous time step plus the delta\n",
        "    # calculated by the model.\n",
        "    return inputs + delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNeH02pspc9B"
      },
      "outputs": [

      ],
      "source": [
        "%%time\n",
        "residual_lstm = ResidualWrapper(\n",
        "    tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    tf.keras.layers.Dense(\n",
        "        num_features,\n",
        "        # The predicted deltas should start small.\n",
        "        # Therefore, initialize the output layer with zeros.\n",
        "        kernel_initializer=tf.initializers.zeros())\n",
        "]))\n",
        "\n",
        "history = compile_and_fit(residual_lstm, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val)\n",
        "performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I42Er9Du6co1"
      },
      "source": [
        "#### Leistung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZxR38P_6pUi"
      },
      "source": [
        "Hier ist die Gesamtleistung für diese Multi-Output-Modelle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XgTK9tnr7rc"
      },
      "outputs": [

      ],
      "source": [
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel('MAE (average over all outputs)')\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URz3ajCc6kBj"
      },
      "outputs": [

      ],
      "source": [
        "for name, value in performance.items():\n",
        "  print(f'{name:15s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vt2MJhNxwPU"
      },
      "source": [
        "Die oben genannten Leistungen sind über alle Modellausgaben gemittelt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYokb7Om2YbK"
      },
      "source": [
        "## Mehrstufige Modelle\n",
        "\n",
        "Sowohl das Single-Output- als auch das Multiple-Output-Modell in den vorherigen Abschnitten machten **Vorhersagen für einzelne Zeitschritte** , eine Stunde in die Zukunft.\n",
        "\n",
        "In diesem Abschnitt wird untersucht, wie diese Modelle erweitert werden können, um **mehrere Zeitschrittvorhersagen** zu machen.\n",
        "\n",
        "Bei einer mehrstufigen Vorhersage muss das Modell lernen, eine Reihe zukünftiger Werte vorherzusagen. Anders als bei einem einstufigen Modell, bei dem nur ein einziger zukünftiger Punkt vorhergesagt wird, sagt ein mehrstufiges Modell eine Folge von zukünftigen Werten voraus.\n",
        "\n",
        "Dazu gibt es zwei grobe Ansätze:\n",
        "\n",
        "1. Einzelschussvorhersagen, bei denen die gesamte Zeitreihe auf einmal vorhergesagt wird.\n",
        "2. Autoregressive Vorhersagen, bei denen das Modell nur Einzelschrittvorhersagen macht und seine Ausgabe als Eingabe zurückgeführt wird.\n",
        "\n",
        "In diesem Abschnitt sagen alle Modelle **alle Merkmale über alle Ausgabezeitschritte hinweg** voraus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFsDAwVt4_rq"
      },
      "source": [
        "Für das mehrstufige Modell bestehen die Trainingsdaten wiederum aus stündlichen Stichproben. Hier werden die Modelle jedoch lernen, 24 Stunden in die Zukunft vorherzusagen, wenn sie 24 Stunden in der Vergangenheit liegen.\n",
        "\n",
        "Hier ist ein `Window` Objekt, das diese Slices aus dem Datensatz generiert:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cFYtsz6XiGw"
      },
      "outputs": [

      ],
      "source": [
        "OUT_STEPS = 24\n",
        "multi_window = WindowGenerator(input_width=24,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS)\n",
        "\n",
        "multi_window.plot()\n",
        "multi_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lg8SInh9Jzd"
      },
      "source": [
        "### Grundlinien"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axwpoWYOApJL"
      },
      "source": [
        "Eine einfache Grundlage für diese Aufgabe besteht darin, den letzten Eingabezeitschritt für die erforderliche Anzahl von Ausgabezeitschritten zu wiederholen:\n",
        "\n",
        "![Wiederholen Sie die letzte Eingabe für jeden Ausgabeschritt](images/multistep_last.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5iaHSaJ9Rxv"
      },
      "outputs": [

      ],
      "source": [
        "class MultiStepLastBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n",
        "\n",
        "last_baseline = MultiStepLastBaseline()\n",
        "last_baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                      metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance = {}\n",
        "multi_performance = {}\n",
        "\n",
        "multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Last'] = last_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(last_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvHZ93ObAfMA"
      },
      "source": [
        "Da diese Aufgabe darin besteht, 24 Stunden in die Zukunft zu prognostizieren, besteht ein weiterer einfacher Ansatz darin, den Vortag zu wiederholen, vorausgesetzt, morgen wird es ähnlich sein:\n",
        "\n",
        "![Am Vortag wiederholen](images/multistep_repeat.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8Y1uMhGwIRs"
      },
      "outputs": [

      ],
      "source": [
        "class RepeatBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return inputs\n",
        "\n",
        "repeat_baseline = RepeatBaseline()\n",
        "repeat_baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                        metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(repeat_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbndS-ct9C2Q"
      },
      "source": [
        "### Single-Shot-Modelle\n",
        "\n",
        "Ein High-Level-Ansatz für dieses Problem ist die Verwendung eines \"Single-Shot\"-Modells, bei dem das Modell die gesamte Sequenzvorhersage in einem einzigen Schritt macht.\n",
        "\n",
        "Dies kann effizient als `tf.keras.layers.Dense` mit `OUT_STEPS*features` -Ausgabeeinheiten implementiert werden. Das Modell muss diese Ausgabe nur in die erforderliche `(OUTPUT_STEPS, features)` ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCKS4m1VKrDQ"
      },
      "source": [
        "#### Linear\n",
        "\n",
        "Ein einfaches lineares Modell, das auf dem letzten Eingabezeitschritt basiert, schneidet besser ab als jede Basislinie, ist aber zu schwach. Das Modell muss `OUTPUT_STEPS` aus einem einzelnen Eingabezeitschritt mit einer linearen Projektion vorhersagen. Es kann nur einen niedrigdimensionalen Teil des Verhaltens erfassen, der wahrscheinlich hauptsächlich auf der Tages- und Jahreszeit basiert.\n",
        "\n",
        "![Sagen Sie alle Zeitschritte ab dem letzten Zeitschritt voraus](images/multistep_dense.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfRz_WVhIQcd"
      },
      "outputs": [

      ],
      "source": [
        "multi_linear_model = tf.keras.Sequential([\n",
        "    # Take the last time-step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_linear_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\n",
        "multi_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_linear_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi2TMHk2IRrh"
      },
      "source": [
        "#### Dicht\n",
        "\n",
        "Das Hinzufügen eines `tf.keras.layers.Dense` zwischen Eingabe und Ausgabe verleiht dem linearen Modell mehr Leistung, basiert aber immer noch nur auf einem einzigen Eingabezeitschritt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jezm-BKaGj91"
      },
      "outputs": [

      ],
      "source": [
        "multi_dense_model = tf.keras.Sequential([\n",
        "    # Take the last time step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, dense_units]\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Shape => [batch, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_dense_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\n",
        "multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_dense_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icsBAjCzMaMl"
      },
      "source": [
        "#### CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34lCZrWYNBwd"
      },
      "source": [
        "Ein Faltungsmodell trifft Vorhersagen auf der Grundlage eines Verlaufs mit fester Breite, was zu einer besseren Leistung als das dichte Modell führen kann, da es sehen kann, wie sich die Dinge im Laufe der Zeit ändern:\n",
        "\n",
        "![Ein Faltungsmodell sieht, wie sich die Dinge im Laufe der Zeit ändern](images/multistep_conv.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xJoIP6PMWMI"
      },
      "outputs": [

      ],
      "source": [
        "CONV_WIDTH = 3\n",
        "multi_conv_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
        "    # Shape => [batch, 1, conv_units]\n",
        "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
        "    # Shape => [batch, 1,  out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_conv_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\n",
        "multi_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_conv_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weBjeZAFJOP4"
      },
      "source": [
        "#### RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8022xOKxOO92"
      },
      "source": [
        "Ein wiederkehrendes Modell kann lernen, eine lange Historie von Eingaben zu verwenden, wenn dies für die Vorhersagen, die das Modell macht, relevant ist. Hier akkumuliert das Modell den internen Zustand für 24 Stunden, bevor es eine einzelne Vorhersage für die nächsten 24 Stunden macht.\n",
        "\n",
        "In diesem Single-Shot-Format muss das LSTM nur im letzten Zeitschritt eine Ausgabe erzeugen, also legen `return_sequences=False` in `tf.keras.layers.LSTM` .\n",
        "\n",
        "![Das LSTM akkumuliert den Zustand über das Eingabefenster und macht eine einzelne Vorhersage für die nächsten 24 Stunden](images/multistep_lstm.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf1ks6RTzF64"
      },
      "outputs": [

      ],
      "source": [
        "multi_lstm_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, lstm_units].\n",
        "    # Adding more `lstm_units` just overfits more quickly.\n",
        "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
        "    # Shape => [batch, out_steps*features].\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features].\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_lstm_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
        "multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(multi_lstm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5n-1cDW12Vo"
      },
      "source": [
        "### Erweitert: Autoregressives Modell\n",
        "\n",
        "Die obigen Modelle sagen alle die gesamte Ausgabesequenz in einem einzigen Schritt voraus.\n",
        "\n",
        "In manchen Fällen kann es für das Modell hilfreich sein, diese Vorhersage in einzelne Zeitschritte zu zerlegen. Dann kann die Ausgabe jedes Modells bei jedem Schritt in sich selbst zurückgeführt werden, und Vorhersagen können abhängig vom vorherigen gemacht werden, wie im klassischen <a href=\"https://arxiv.org/abs/1308.0850\" class=\"external\">Generieren von Sequenzen mit rekurrenten neuronalen Netzen</a> .\n",
        "\n",
        "Ein klarer Vorteil dieses Modelltyps besteht darin, dass es so eingerichtet werden kann, dass es eine Ausgabe mit unterschiedlicher Länge erzeugt.\n",
        "\n",
        "Sie könnten jedes der Einzelschritt-Modelle mit mehreren Ausgaben, die in der ersten Hälfte dieses Tutorials trainiert wurden, nehmen und in einer autoregressiven Rückkopplungsschleife ausführen, aber hier konzentrieren Sie sich auf die Erstellung eines Modells, das explizit dafür trainiert wurde.\n",
        "\n",
        "![Geben Sie die Ausgabe eines Modells an seine Eingabe zurück](images/multistep_autoregressive.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKRreBbULRXY"
      },
      "source": [
        "#### RNN\n",
        "\n",
        "In diesem Lernprogramm wird nur ein autoregressives RNN-Modell erstellt, aber dieses Muster könnte auf jedes Modell angewendet werden, das für die Ausgabe eines einzelnen Zeitschritts ausgelegt ist.\n",
        "\n",
        "Das Modell hat die gleiche Grundform wie die einstufigen LSTM-Modelle von früher: eine `tf.keras.layers.LSTM` Schicht, gefolgt von einer `tf.keras.layers.Dense` Schicht, die die Ausgaben der `LSTM` -Schicht in Modellvorhersagen umwandelt.\n",
        "\n",
        "Ein `tf.keras.layers.LSTM` ist eine `tf.keras.layers.LSTMCell` , die in die übergeordnete `tf.keras.layers.RNN` ist, die den Status und die Sequenzergebnisse für Sie verwaltet (Schauen Sie sich die [Recurrent Neural Networks (RNN) mit Keras an](https://www.tensorflow.org/guide/keras/rnn) Anleitung für Details).\n",
        "\n",
        "In diesem Fall muss das Modell die Eingaben für jeden Schritt manuell verwalten, daher verwendet es `tf.keras.layers.LSTMCell` direkt für die Einzelzeitschrittschnittstelle auf niedrigerer Ebene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5tz3Nu0R5JG"
      },
      "outputs": [

      ],
      "source": [
        "class FeedBack(tf.keras.Model):\n",
        "  def __init__(self, units, out_steps):\n",
        "    super().__init__()\n",
        "    self.out_steps = out_steps\n",
        "    self.units = units\n",
        "    self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
        "    # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
        "    self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OXVM9G1U7xR"
      },
      "outputs": [

      ],
      "source": [
        "feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph5uFSfTUNho"
      },
      "source": [
        "Die erste Methode, die dieses Modell benötigt, ist eine `warmup` , um seinen internen Zustand basierend auf den Eingaben zu initialisieren. Einmal trainiert, erfasst dieser Zustand die relevanten Teile der Eingabehistorie. Dies entspricht dem einstufigen `LSTM` -Modell von früher:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM2K_LLdRjDZ"
      },
      "outputs": [

      ],
      "source": [
        "def warmup(self, inputs):\n",
        "  # inputs.shape => (batch, time, features)\n",
        "  # x.shape => (batch, lstm_units)\n",
        "  x, *state = self.lstm_rnn(inputs)\n",
        "\n",
        "  # predictions.shape => (batch, features)\n",
        "  prediction = self.dense(x)\n",
        "  return prediction, state\n",
        "\n",
        "FeedBack.warmup = warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JkaSYaZ9eB7"
      },
      "source": [
        "Diese Methode gibt eine einzelne Zeitschrittvorhersage und den internen Zustand des `LSTM` zurück:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9Fz6NTKXXwU"
      },
      "outputs": [

      ],
      "source": [
        "prediction, state = feedback_model.warmup(multi_window.example[0])\n",
        "prediction.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_ZdvPjdX3y3"
      },
      "source": [
        "Mit dem Zustand des `RNN` und einer anfänglichen Vorhersage können Sie nun mit der Iteration des Modells fortfahren und die Vorhersagen bei jedem Schritt zurück als Eingabe füttern.\n",
        "\n",
        "Der einfachste Ansatz zum Sammeln der Ausgabevorhersagen besteht darin, eine Python-Liste und einen `tf.stack` nach der Schleife zu verwenden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yotTad3nZXQU"
      },
      "source": [
        "Hinweis: Das Stapeln einer Python-Liste auf diese Weise funktioniert nur mit Eager-Ausführung, mit `Model.compile(..., run_eagerly=True)` für das Training oder mit einer Ausgabe mit fester Länge. Für eine dynamische Ausgabelänge müssten Sie ein `tf.TensorArray` anstelle einer Python-Liste und `tf.range` anstelle des Python `range` verwenden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1GRDu3mZtr9"
      },
      "outputs": [

      ],
      "source": [
        "def call(self, inputs, training=None):\n",
        "  # Use a TensorArray to capture dynamically unrolled outputs.\n",
        "  predictions = []\n",
        "  # Initialize the LSTM state.\n",
        "  prediction, state = self.warmup(inputs)\n",
        "\n",
        "  # Insert the first prediction.\n",
        "  predictions.append(prediction)\n",
        "\n",
        "  # Run the rest of the prediction steps.\n",
        "  for n in range(1, self.out_steps):\n",
        "    # Use the last prediction as input.\n",
        "    x = prediction\n",
        "    # Execute one lstm step.\n",
        "    x, state = self.lstm_cell(x, states=state,\n",
        "                              training=training)\n",
        "    # Convert the lstm output to a prediction.\n",
        "    prediction = self.dense(x)\n",
        "    # Add the prediction to the output.\n",
        "    predictions.append(prediction)\n",
        "\n",
        "  # predictions.shape => (time, batch, features)\n",
        "  predictions = tf.stack(predictions)\n",
        "  # predictions.shape => (batch, time, features)\n",
        "  predictions = tf.transpose(predictions, [1, 0, 2])\n",
        "  return predictions\n",
        "\n",
        "FeedBack.call = call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubop-YWp15XW"
      },
      "source": [
        "Testen Sie dieses Modell mit den Beispieleingaben:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xja83zEYaM2D"
      },
      "outputs": [

      ],
      "source": [
        "print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMs0rYB8be9M"
      },
      "source": [
        "Trainieren Sie nun das Modell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBRVG2hnNyrO"
      },
      "outputs": [

      ],
      "source": [
        "history = compile_and_fit(feedback_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)\n",
        "multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot(feedback_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGjcJsAQJUkI"
      },
      "source": [
        "### Leistung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODAwr2ndtDB"
      },
      "source": [
        "Bei diesem Problem gibt es deutlich abnehmende Renditen als Funktion der Modellkomplexität:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZwWBA8S6B3L"
      },
      "outputs": [

      ],
      "source": [
        "x = np.arange(len(multi_performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in multi_val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in multi_performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=multi_performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel(f'MAE (average over all times and outputs)')\n",
        "_ = plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq3hUsedCEmJ"
      },
      "source": [
        "Die Metriken für die Multi-Output-Modelle in der ersten Hälfte dieses Tutorials zeigen die über alle Ausgabefeatures gemittelte Leistung. Diese Leistungen sind ähnlich, aber auch über Ausgabezeitschritte gemittelt. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKq3eAIvH4Db"
      },
      "outputs": [

      ],
      "source": [
        "for name, value in multi_performance.items():\n",
        "  print(f'{name:8s}: {value[1]:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpBFwfnaHP23"
      },
      "source": [
        "Die erzielten Gewinne beim Übergang von einem dichten Modell zu Faltungs- und rekurrenten Modellen betragen nur wenige Prozent (wenn überhaupt), und das autoregressive Modell schnitt deutlich schlechter ab. Diese komplexeren Ansätze lohnen sich also möglicherweise nicht für **dieses** Problem, aber es gab keine Möglichkeit, dies zu wissen, ohne es zu versuchen, und diese Modelle könnten für **Ihr** Problem hilfreich sein."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOzaIRYBhqwg"
      },
      "source": [
        "## Nächste Schritte\n",
        "\n",
        "Dieses Tutorial war eine kurze Einführung in die Zeitreihenprognose mit TensorFlow.\n",
        "\n",
        "Weitere Informationen finden Sie unter:\n",
        "\n",
        "- Kapitel 15 von <a href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\" class=\"external\">Praktisches maschinelles Lernen mit Scikit-Learn, Keras und TensorFlow</a> , 2. Auflage.\n",
        "- Kapitel 6 von <a href=\"https://www.manning.com/books/deep-learning-with-python\" class=\"external\">Deep Learning mit Python</a> .\n",
        "- Lektion 8 von <a href=\"https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187\" class=\"external\">Udacitys Einführung in TensorFlow für Deep Learning</a> , einschließlich der <a href=\"https://github.com/tensorflow/examples/tree/master/courses/udacity_intro_to_tensorflow_for_deep_learning\" class=\"external\">Übungshefte</a> .\n",
        "\n",
        "Denken Sie auch daran, dass Sie jedes <a href=\"https://otexts.com/fpp2/index.html\" class=\"external\">klassische Zeitreihenmodell</a> in TensorFlow implementieren können – dieses Tutorial konzentriert sich nur auf die integrierten Funktionen von TensorFlow.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [

      ],
      "name": "time_series.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
